{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tutorial for MCMC SED Analysis",
   "id": "6a01dd90799c6eb9"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-19T22:34:02.737907Z",
     "start_time": "2025-06-19T22:34:02.599248Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 9,
   "source": [
    "# import warnings, os\n",
    "# warnings.filterwarnings('ignore')\n",
    "# os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "import os\n",
    "from mcmcsedanalysis.mcmc import MCMC,run\n",
    "from mcmcanalysis import mcmc_utils\n",
    "from mcmcsedanalysis import show_priors\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from mcmcanalysis.synthetic_photometry import load_spectra_task,plot_SEDfit\n",
    "from synphot import SourceSpectrum,SpectralElement,Empirical1D\n",
    "import concurrent.futures\n",
    "from glob import glob\n",
    "from itertools import repeat\n",
    "from astropy.time import Time\n",
    "import stsynphot as stsyn\n",
    "import pickle\n",
    "import ruamel.yaml\n",
    "yaml = ruamel.yaml.YAML()"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load(file):\n",
    "    if not isinstance(file, str):\n",
    "        return file\n",
    "\n",
    "    if file.lower().endswith(('yaml', 'yml')):\n",
    "        with open(file, 'r') as f:\n",
    "            ret = yaml.load(f)\n",
    "        return ret\n",
    "\n",
    "def assembling_spectra_dataframes(path2accr_spect,path2models,path2models_w_acc,acc_spec_filename = 'accretion_spectrum_2016.fits'):\n",
    "    ### Accr Spectrum\n",
    "    spAcc = SourceSpectrum.from_file(path2accr_spect + '/' + acc_spec_filename)\n",
    "\n",
    "    ### Load Spectra without accretium from file\n",
    "    file_list = sorted(glob(path2models + \"/*.dat\"))\n",
    "    spectrum_list = []\n",
    "    T_list = []\n",
    "    logg_list = []\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "        for spectrum, temp, logg in tqdm(executor.map(load_spectra_task, file_list, repeat(False))):\n",
    "            if temp / 100 % 1 == 0:\n",
    "                spectrum_list.append(spectrum)\n",
    "                T_list.append(temp)\n",
    "                logg_list.append(logg)\n",
    "    spectrum_without_acc_df = pd.DataFrame({'Teff': T_list, 'logg': logg_list, 'Spectrum': spectrum_list}).set_index(\n",
    "        ['Teff', 'logg']).sort_values(['Teff', 'logg'])\n",
    "\n",
    "    ### Load Spectra with accretium from file\n",
    "    file_list = sorted(glob(path2models_w_acc + \"/*.dat\"))\n",
    "    spectrum_list = []\n",
    "    T_list = []\n",
    "    logg_list = []\n",
    "    logAcc_list = []\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(max_workers=10) as executor:\n",
    "        for spectrum, temp, logg, logacc in tqdm(executor.map(load_spectra_task, file_list, repeat(True))):\n",
    "            if temp / 100 % 1 == 0:\n",
    "                spectrum_list.append(spectrum)\n",
    "                T_list.append(temp)\n",
    "                logg_list.append(logg)\n",
    "                logAcc_list.append(logacc)\n",
    "\n",
    "    spectrum_with_acc_df = pd.DataFrame(\n",
    "        {'Teff': T_list, 'logg': logg_list, 'logAcc': logAcc_list, 'Spectrum': spectrum_list}).set_index(\n",
    "        ['Teff', 'logg', 'logAcc']).sort_values(['Teff', 'logg', 'logAcc'])\n",
    "\n",
    "    ### Vega Spectrum\n",
    "    vega_spectrum = SourceSpectrum.from_vega()\n",
    "    # vega_spectrum.plot(left=2000, right=20000, flux_unit='flam', title=vega_spectrum.meta['expr'])\n",
    "    return(spAcc,spectrum_with_acc_df,spectrum_without_acc_df,vega_spectrum)\n",
    "\n",
    "def interpolating_isochrones(path2iso, mag_label_list, redo=False, smooth=0.001, method='linear', showplot=False):\n",
    "    if redo:\n",
    "        ## Isochrones ((skip if already saved))\n",
    "        iso_df=pd.read_hdf(path2iso+\"bt_settl_AGSS2009_isochrones_new_acc_final.h5\",'df')\n",
    "        iso_df=iso_df.loc[np.isfinite(iso_df.logLacc.values)]\n",
    "\n",
    "        node_label_list= list(mag_label_list)+['teff','logL','logg','logLacc','logMacc','R']\n",
    "        node_list=[iso_df[label].values.ravel() for label in node_label_list]\n",
    "        x=np.log10(iso_df['mass'].values).ravel()\n",
    "        y=np.log10(iso_df.index.get_level_values('Age').values).ravel()\n",
    "        z=iso_df.index.get_level_values('logAcc').values.ravel()\n",
    "\n",
    "        interp_btsettl= mcmc_utils.interpND([x, y, z, node_list], method=method, showplot=showplot, smooth=smooth, z_label=node_label_list, workers=5)\n",
    "\n",
    "        with open(path2iso+\"interpolated_isochrones.pck\", 'wb') as file_handle:\n",
    "            pickle.dump(interp_btsettl , file_handle)\n",
    "    else:\n",
    "        ## Load interpolated isochrones\n",
    "        with open(path2iso + \"interpolated_isochrones.pck\", 'rb') as file_handle:\n",
    "            interp_btsettl = pickle.load(file_handle)\n",
    "    return (interp_btsettl)\n",
    "\n",
    "def assembling_dictionaries(filter_list,mag_label_list,sat_list, Rv):\n",
    "    ## Extinction\n",
    "    Av_dict = mcmc_utils.get_Av_list(filter_list, verbose=False, Rv=Rv)\n",
    "\n",
    "    ## Saturation\n",
    "    sat_dict = dict(zip(mag_label_list, sat_list))\n",
    "\n",
    "    ## BP dictionary\n",
    "    obsdate = Time('2005-01-1').mjd\n",
    "    bp336 = stsyn.band('acs,wfpc2,f336w')\n",
    "    bp439 = stsyn.band('acs,wfpc2,f439w')\n",
    "    bp656 = stsyn.band('acs,wfpc2,f656n')\n",
    "    bp814 = stsyn.band('acs,wfpc2,f814w')\n",
    "\n",
    "    bp435 = stsyn.band(f'acs,wfc1,f435w,mjd#{obsdate}')\n",
    "    bp555 = stsyn.band(f'acs,wfc1,f555w,mjd#{obsdate}')\n",
    "    bp658 = stsyn.band(f'acs,wfc1,f658n,mjd#{obsdate}')\n",
    "    bp775 = stsyn.band(f'acs,wfc1,f775w,mjd#{obsdate}')\n",
    "    bp850 = stsyn.band(f'acs,wfc1,f850lp,mjd#{obsdate}')\n",
    "\n",
    "    bp110 = stsyn.band('nicmos,3,f110w')\n",
    "    bp160 = stsyn.band('nicmos,3,f160w')\n",
    "\n",
    "    bp130 = stsyn.band('wfc3,ir,f130n')\n",
    "    bp139 = stsyn.band('wfc3,ir,f139m')\n",
    "\n",
    "    bp_list = [bp336, bp439, bp656, bp814, bp435, bp555, bp658, bp775, bp850, bp110, bp160, bp130, bp139]\n",
    "\n",
    "    bp_flattened_list = []\n",
    "    for bp in bp_list:\n",
    "        bp_flattened = SpectralElement(Empirical1D, points=bp.waveset,\n",
    "                                       lookup_table=bp(bp.waveset))\n",
    "        bp_flattened_list.append(bp_flattened)\n",
    "    bp_dict = {'%s' % mag_label_list[elno]: bp_flattened_list[elno] for elno in range(len(mag_label_list))}\n",
    "    return(Av_dict,sat_dict,bp_dict)\n",
    "\n",
    "def assembling_priors(path2data,showplot=False):\n",
    "    Besançon_plus_GAIA_ONCFOV_df = pd.read_csv(path2data + '/Besançon_plus_GAIA_ONCFOV.csv')\n",
    "    parallax_KDE0 = show_priors.kernel_prior(Besançon_plus_GAIA_ONCFOV_df.parallax, xlabel='parallax', nbins=50,\n",
    "                                             bw_method=0.1, bandwidth2fit=np.linspace(0.01, 0.1, 1000),\n",
    "                                             xlogscale=False, showplot=showplot,\n",
    "                                             density=True, kernel='gaussian', return_prior=True)\n",
    "\n",
    "    Av_df = pd.read_csv(path2data + '/Av.csv')\n",
    "    Av_KDE0 = show_priors.kernel_prior(Av_df.Av, xlabel='Av', nbins=10, bw_method=0.2,\n",
    "                                       bandwidth2fit=np.linspace(0.1, 3, 1000), xlogscale=False, density=True,\n",
    "                                       kernel='gaussian', return_prior=True, showplot=showplot, )\n",
    "\n",
    "    Age_df = pd.read_csv(path2data + '/Age.csv')\n",
    "    Age_KDE0 = show_priors.kernel_prior(Age_df.Age, xlabel='A', nbins=20, bw_method=0.3,\n",
    "                                        bandwidth2fit=np.linspace(0.1, 3, 1000), xlogscale=False, density=True,\n",
    "                                        kernel='gaussian', return_prior=True, showplot=showplot, )\n",
    "    Mass_df = pd.read_csv(path2data + '/Mass.csv')\n",
    "\n",
    "    mass_KDE0 = show_priors.kernel_prior(Mass_df.Mass, xlabel='mass', nbins=10, bw_method=0.08,\n",
    "                                         bandwidth2fit=np.linspace(0.1, 1, 1000), xlogscale=False, density=True,\n",
    "                                         kernel='gaussian', return_prior=True, showplot=showplot, )\n",
    "    return(parallax_KDE0, Av_KDE0, Age_df, Age_KDE0, mass_KDE0)"
   ],
   "id": "e4ab5aad9e59b286"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\n",
    "    config = load('/pipeline_logs/mcmc.yaml')\n",
    "    path2data = config['paths']['data']\n",
    "    path2priors = config['paths']['priors']\n",
    "    path2accr_spect = config['paths']['accr_spect']\n",
    "    path2models = config['paths']['models']\n",
    "    path2models_w_acc = config['paths']['models_w_acc']\n",
    "    path2iso = config['paths']['iso']\n",
    "    catalogue = config['catalogue']['name']\n",
    "\n",
    "    ################################################################################################################\n",
    "    # Making output dirs                                                                                            #\n",
    "    ################################################################################################################\n",
    "    os.makedirs(path2data+'/analysis/samplers', exist_ok=True)\n",
    "    os.makedirs(path2data+'/analysis/corners', exist_ok=True)\n",
    "    os.makedirs(path2data+'/analysis/fits', exist_ok=True)\n",
    "\n",
    "    ################################################################################################################\n",
    "    # Importing Catalog                                                                                            #\n",
    "    ################################################################################################################\n",
    "    input_df = pd.read_csv(path2data + catalogue)\n",
    "    ################################################################################################################\n",
    "    # Setting the stage for the MCMC run                                                                           #\n",
    "    ################################################################################################################\n",
    "    # Selecting the filters and saturation limits and magnitudes to work with from the catalog\n",
    "    filter_list = config['filter_list']\n",
    "    sat_list = config['sat_list']\n",
    "    Rv = config['Rv']\n",
    "    ID_label = config['ID_label']\n",
    "    mag_label_list =  ['m' + i[1:4] for i in filter_list]\n",
    "    emag_label_list =  ['e' + i[1:4] for i in filter_list]\n",
    "\n",
    "    #Interpolating Isochrones on the selected magnitudes (or load an existing interpolated isochrone)\n",
    "    interp_btsettl = interpolating_isochrones(path2iso,mag_label_list)\n",
    "    # Creating a filter dependent dictionary for the extinction, saturation and bandpass\n",
    "    Av_dict, sat_dict, bp_dict = assembling_dictionaries(filter_list,mag_label_list,sat_list,Rv)\n",
    "\n",
    "    # Loading KDE for priors to use as general priors in case specific prior for the target is missing.\n",
    "    # Note: If you have the prior for Teff, it will skip the KDE prior on the mass.\n",
    "    parallax_KDE0, Av_KDE0, Age_df, Age_KDE0, mass_KDE0 = assembling_priors(path2priors)\n",
    "\n",
    "    ID_list = config['ID_list']\n",
    "    #To add prior knowledge for the star's parameters we need to add the following entry to the catalog.\n",
    "    # If any of these values are nans, or absent, then the pipeline will use the KDEs if provided.\n",
    "    # If they are None, then no prior will be used for that parameter.\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'Parallax'] = 2.768875\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'eParallax'] = 150\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'Teff'] = 3402\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'eTeff'] = 150\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'Av'] = 3.17\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'eAv'] = 1\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'Age'] = 4.56\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'eAge'] = 1\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'SpAcc'] = 0.042\n",
    "    input_df.loc[input_df[ID_label].isin(ID_list), 'eSpAcc'] = 0.5\n",
    "\n",
    "    ################################################################################################################\n",
    "    # This is the start of the MCMC run                                                                            #\n",
    "    ################################################################################################################\n",
    "\n",
    "    display(input_df.loc[input_df[ID_label].isin(ID_list)])\n",
    "\n",
    "    mcmc=MCMC(interp_btsettl,\n",
    "              mag_label_list,\n",
    "              sat_dict,\n",
    "              Av_dict,\n",
    "              emag_label_list= emag_label_list,\n",
    "              ID_label=ID_label,\n",
    "              Teff_label=config['MCMC']['Teff_label'],\n",
    "              eTeff_label=config['MCMC']['eTeff_label'],\n",
    "              parallax_label=config['MCMC']['parallax_label'],\n",
    "              eparallax_label=config['MCMC']['eparallax_label'],\n",
    "              Av_label=config['MCMC']['Av_label'],\n",
    "              eAv_label=config['MCMC']['eAv_label'],\n",
    "              Age_label=config['MCMC']['Age_label'],\n",
    "              eAge_label=config['MCMC']['eAge_label'],\n",
    "              SpAcc_label=config['MCMC']['SpAcc_label'],\n",
    "              eSpAcc_label=config['MCMC']['eSpAcc_label'],\n",
    "              workers=config['MCMC']['workers'],\n",
    "              conv_thr=config['MCMC']['conv_thr'],\n",
    "              ndesired=config['MCMC']['ndesired'],\n",
    "              err_max=config['MCMC']['err_max'],\n",
    "              err_min=config['MCMC']['err_min'],\n",
    "              logMass_range=config['MCMC']['logMass_range'],\n",
    "              logAge_range=config['MCMC']['logAge_range'],\n",
    "              logSPacc_range=config['MCMC']['logSPacc_range'],\n",
    "              logAv_range=config['MCMC']['logAv_range'],\n",
    "              Parallax_range=config['MCMC']['parallax_range'],\n",
    "              nwalkers_ndim_niters=config['MCMC']['nwalkers_ndim_niters'],\n",
    "              parallelize_sampler=config['MCMC']['parallelize_sampler'],\n",
    "              show_test=config['MCMC']['show_test'],\n",
    "              progress=config['MCMC']['progress'],\n",
    "              blobs=config['MCMC']['blobs'],\n",
    "              parallax_KDE=parallax_KDE0,\n",
    "              Av_KDE=Av_KDE0,\n",
    "              Age_KDE=Age_KDE0,\n",
    "              mass_KDE=mass_KDE0,\n",
    "              path2data=path2data,\n",
    "              savedir=path2data+'/analysis/samplers') # ----> This will setup the MCMC. There are many options hidden in there!\n",
    "\n",
    "    run(mcmc, input_df, ID_list,forced=True) # ---> This will run the MCMC and save the sampler"
   ],
   "id": "b0a31f7736f5ebfc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "################################################################################################################\n",
    "# This part is very specific for my ONC Work.                                                                  #\n",
    "# I used these routines to update the DF with the generated new values and draw the summary plots.             #\n",
    "# You can always read the sampler in the samplers dir and sample the posterior and generate your own plots     #\n",
    "# skipping entirely this section.                                                                              #\n",
    "################################################################################################################\n",
    "\n",
    "# Loading the posterior distributions saved in the sampler\n",
    "file_list=[]\n",
    "for ID in tqdm(ID_list):\n",
    "    file_list.append(path2data + f\"/analysis/samplers/samplerID_{ID}\")\n",
    "\n",
    "################################################################################################################\n",
    "# I use these values to sample the sampler, plot corner plots and trace plots,                                 #\n",
    "# and evaluate if the distance for my source is compatible with Orion                                          #\n",
    "################################################################################################################\n",
    "pmean = config['MCMC']['pmean']\n",
    "pM = config['MCMC']['pM']\n",
    "pm = config['MCMC']['pm']\n",
    "\n",
    "# Sampling posteriors\n",
    "input_df = mcmc_utils.update_dataframe(input_df, file_list, interp_btsettl, kde_fit=True, ID_label=ID_label,\n",
    "                                       pmin=pmean - pm * 3, pmax=pmean + pM * 3, path2loaddir=path2data+'/analysis/samplers',\n",
    "                                       path2savedir=path2data+'/analysis/corners', parallel_runs=False, verbose=True)\n",
    "\n",
    "################################################################################################################\n",
    "# Saving summary plot                                                                                          #\n",
    "################################################################################################################\n",
    "\n",
    "# Assembling Spectra dataframes for final plots\n",
    "spAcc, spectrum_with_acc_df, spectrum_without_acc_df, vega_spectrum = assembling_spectra_dataframes(path2accr_spect, path2models, path2models_w_acc)\n",
    "for ID in tqdm(ID_list):\n",
    "    file = path2data+'/analysis/corners/cornerID%i.png' % int(ID)\n",
    "    img = mpimg.imread(file)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    fig, ax[0], Ndict = plot_SEDfit(spAcc, spectrum_without_acc_df, vega_spectrum, bp_dict,\n",
    "                                    sat_dict, interp_btsettl, input_df.loc[input_df[ID_label] == ID],\n",
    "                                    mag_label_list, Rv=Rv, ms=2, showplot=False, fig=fig, ax=ax[0])\n",
    "    ax[1].imshow(img)\n",
    "    ax[1].axis('off')\n",
    "    fig.suptitle(int(ID))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path2data+'/analysis/fits/ID%i.png' % int(ID))\n",
    "    plt.close()"
   ],
   "id": "d503b7be52f9d85b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
